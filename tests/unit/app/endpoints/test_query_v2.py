# pylint: disable=redefined-outer-name, import-error
"""Unit tests for the /query (v2) REST API endpoint using Responses API."""

import pytest
from fastapi import HTTPException, status, Request

from llama_stack_client import APIConnectionError

from models.requests import QueryRequest, Attachment
from models.config import ModelContextProtocolServer

from app.endpoints.query_v2 import (
    get_rag_tools,
    get_mcp_tools,
    retrieve_response,
    query_endpoint_handler_v2,
)


@pytest.fixture
def dummy_request() -> Request:
    """Create a dummy FastAPI Request object for testing."""
    req = Request(scope={"type": "http"})
    return req


def test_get_rag_tools():
    """Test get_rag_tools returns None for empty list and correct tool format for vector stores."""
    assert get_rag_tools([]) is None

    tools = get_rag_tools(["db1", "db2"])
    assert isinstance(tools, list)
    assert tools[0]["type"] == "file_search"
    assert tools[0]["vector_store_ids"] == ["db1", "db2"]
    assert tools[0]["max_num_results"] == 10


def test_get_mcp_tools_with_and_without_token():
    """Test get_mcp_tools generates correct tool definitions with and without auth tokens."""
    servers = [
        ModelContextProtocolServer(name="fs", url="http://localhost:3000"),
        ModelContextProtocolServer(name="git", url="https://git.example.com/mcp"),
    ]

    tools_no_token = get_mcp_tools(servers, token=None)
    assert len(tools_no_token) == 2
    assert tools_no_token[0]["type"] == "mcp"
    assert tools_no_token[0]["server_label"] == "fs"
    assert tools_no_token[0]["server_url"] == "http://localhost:3000"
    assert "headers" not in tools_no_token[0]

    tools_with_token = get_mcp_tools(servers, token="abc")
    assert len(tools_with_token) == 2
    assert tools_with_token[1]["type"] == "mcp"
    assert tools_with_token[1]["server_label"] == "git"
    assert tools_with_token[1]["server_url"] == "https://git.example.com/mcp"
    assert tools_with_token[1]["headers"] == {"Authorization": "Bearer abc"}


@pytest.mark.asyncio
async def test_retrieve_response_no_tools_bypasses_tools(mocker):
    """Test that no_tools=True bypasses tool configuration and passes None to responses API."""
    mock_client = mocker.Mock()
    # responses.create returns a synthetic OpenAI-like response
    response_obj = mocker.Mock()
    response_obj.id = "resp-1"
    response_obj.output = []
    response_obj.usage = None  # No usage info
    mock_client.responses.create = mocker.AsyncMock(return_value=response_obj)
    # vector_stores.list should not matter when no_tools=True, but keep it valid
    mock_vector_stores = mocker.Mock()
    mock_vector_stores.data = []
    mock_client.vector_stores.list = mocker.AsyncMock(return_value=mock_vector_stores)

    # Ensure system prompt resolution does not require real config
    mocker.patch("app.endpoints.query_v2.get_system_prompt", return_value="PROMPT")
    mocker.patch("app.endpoints.query_v2.configuration", mocker.Mock(mcp_servers=[]))

    qr = QueryRequest(query="hello", no_tools=True)
    summary, conv_id, referenced_docs, token_usage = await retrieve_response(
        mock_client, "model-x", qr, token="tkn"
    )

    assert conv_id == "resp-1"
    assert summary.llm_response == ""
    assert referenced_docs == []
    assert token_usage.input_tokens == 0  # No usage info, so 0
    assert token_usage.output_tokens == 0
    # tools must be passed as None
    kwargs = mock_client.responses.create.call_args.kwargs
    assert kwargs["tools"] is None
    assert kwargs["model"] == "model-x"
    assert kwargs["instructions"] == "PROMPT"


@pytest.mark.asyncio
async def test_retrieve_response_builds_rag_and_mcp_tools(mocker):
    """Test that retrieve_response correctly builds RAG and MCP tools from configuration."""
    mock_client = mocker.Mock()
    response_obj = mocker.Mock()
    response_obj.id = "resp-2"
    response_obj.output = []
    response_obj.usage = None
    mock_client.responses.create = mocker.AsyncMock(return_value=response_obj)
    mock_vector_stores = mocker.Mock()
    mock_vector_stores.data = [mocker.Mock(id="dbA")]
    mock_client.vector_stores.list = mocker.AsyncMock(return_value=mock_vector_stores)

    mocker.patch("app.endpoints.query_v2.get_system_prompt", return_value="PROMPT")
    mock_cfg = mocker.Mock()
    mock_cfg.mcp_servers = [
        ModelContextProtocolServer(name="fs", url="http://localhost:3000"),
    ]
    mocker.patch("app.endpoints.query_v2.configuration", mock_cfg)

    qr = QueryRequest(query="hello")
    _summary, conv_id, referenced_docs, token_usage = await retrieve_response(
        mock_client, "model-y", qr, token="mytoken"
    )

    assert conv_id == "resp-2"
    assert referenced_docs == []
    assert token_usage.input_tokens == 0  # No usage info, so 0
    assert token_usage.output_tokens == 0

    kwargs = mock_client.responses.create.call_args.kwargs
    tools = kwargs["tools"]
    assert isinstance(tools, list)
    # Expect one file_search and one mcp tool
    tool_types = {t.get("type") for t in tools}
    assert tool_types == {"file_search", "mcp"}
    file_search = next(t for t in tools if t["type"] == "file_search")
    assert file_search["vector_store_ids"] == ["dbA"]
    mcp_tool = next(t for t in tools if t["type"] == "mcp")
    assert mcp_tool["server_label"] == "fs"
    assert mcp_tool["headers"] == {"Authorization": "Bearer mytoken"}


@pytest.mark.asyncio
async def test_retrieve_response_parses_output_and_tool_calls(mocker):
    """Test that retrieve_response correctly parses output content and tool calls from response."""
    mock_client = mocker.Mock()

    # Build output with content variants and tool calls
    output_item_1 = mocker.Mock()
    output_item_1.type = "message"
    output_item_1.role = "assistant"
    output_item_1.content = [mocker.Mock(text="Hello "), mocker.Mock(text="world")]

    output_item_2 = mocker.Mock()
    output_item_2.type = "message"
    output_item_2.role = "assistant"
    output_item_2.content = "!"

    # Tool call as a separate output item (Responses API format)
    tool_call_item = mocker.Mock()
    tool_call_item.type = "function_call"
    tool_call_item.id = "tc-1"
    tool_call_item.name = "do_something"
    tool_call_item.arguments = {"x": 1}
    tool_call_item.status = None  # Explicitly set to avoid Mock auto-creation

    response_obj = mocker.Mock()
    response_obj.id = "resp-3"
    response_obj.output = [output_item_1, output_item_2, tool_call_item]
    response_obj.usage = None

    mock_client.responses.create = mocker.AsyncMock(return_value=response_obj)
    mock_vector_stores = mocker.Mock()
    mock_vector_stores.data = []
    mock_client.vector_stores.list = mocker.AsyncMock(return_value=mock_vector_stores)

    mocker.patch("app.endpoints.query_v2.get_system_prompt", return_value="PROMPT")
    mocker.patch("app.endpoints.query_v2.configuration", mocker.Mock(mcp_servers=[]))

    qr = QueryRequest(query="hello")
    summary, conv_id, referenced_docs, token_usage = await retrieve_response(
        mock_client, "model-z", qr, token="tkn"
    )

    assert conv_id == "resp-3"
    assert summary.llm_response == "Hello world!"
    assert len(summary.tool_calls) == 1
    assert summary.tool_calls[0].id == "tc-1"
    assert summary.tool_calls[0].name == "do_something"
    assert summary.tool_calls[0].args == {"x": 1}
    assert referenced_docs == []
    assert token_usage.input_tokens == 0  # No usage info, so 0
    assert token_usage.output_tokens == 0


@pytest.mark.asyncio
async def test_retrieve_response_with_usage_info(mocker):
    """Test that token usage is extracted when provided by the API as an object."""
    mock_client = mocker.Mock()

    output_item = mocker.Mock()
    output_item.type = "message"
    output_item.role = "assistant"
    output_item.content = "Test response"
    output_item.tool_calls = []

    # Mock usage information as object
    mock_usage = mocker.Mock()
    mock_usage.input_tokens = 150
    mock_usage.output_tokens = 75

    response_obj = mocker.Mock()
    response_obj.id = "resp-with-usage"
    response_obj.output = [output_item]
    response_obj.usage = mock_usage

    mock_client.responses.create = mocker.AsyncMock(return_value=response_obj)
    mock_vector_stores = mocker.Mock()
    mock_vector_stores.data = []
    mock_client.vector_stores.list = mocker.AsyncMock(return_value=mock_vector_stores)

    mocker.patch("app.endpoints.query_v2.get_system_prompt", return_value="PROMPT")
    mocker.patch("app.endpoints.query_v2.configuration", mocker.Mock(mcp_servers=[]))

    qr = QueryRequest(query="hello")
    summary, conv_id, _referenced_docs, token_usage = await retrieve_response(
        mock_client, "model-usage", qr, token="tkn", provider_id="test-provider"
    )

    assert conv_id == "resp-with-usage"
    assert summary.llm_response == "Test response"
    assert token_usage.input_tokens == 150
    assert token_usage.output_tokens == 75
    assert token_usage.llm_calls == 1


@pytest.mark.asyncio
async def test_retrieve_response_with_usage_dict(mocker):
    """Test that token usage is extracted when provided by the API as a dict."""
    mock_client = mocker.Mock()

    output_item = mocker.Mock()
    output_item.type = "message"
    output_item.role = "assistant"
    output_item.content = "Test response dict"
    output_item.tool_calls = []

    # Mock usage information as dict (like llama stack does)
    response_obj = mocker.Mock()
    response_obj.id = "resp-with-usage-dict"
    response_obj.output = [output_item]
    response_obj.usage = {"input_tokens": 200, "output_tokens": 100}

    mock_client.responses.create = mocker.AsyncMock(return_value=response_obj)
    mock_vector_stores = mocker.Mock()
    mock_vector_stores.data = []
    mock_client.vector_stores.list = mocker.AsyncMock(return_value=mock_vector_stores)

    mocker.patch("app.endpoints.query_v2.get_system_prompt", return_value="PROMPT")
    mocker.patch("app.endpoints.query_v2.configuration", mocker.Mock(mcp_servers=[]))

    qr = QueryRequest(query="hello")
    summary, conv_id, _referenced_docs, token_usage = await retrieve_response(
        mock_client, "model-usage-dict", qr, token="tkn", provider_id="test-provider"
    )

    assert conv_id == "resp-with-usage-dict"
    assert summary.llm_response == "Test response dict"
    assert token_usage.input_tokens == 200
    assert token_usage.output_tokens == 100
    assert token_usage.llm_calls == 1


@pytest.mark.asyncio
async def test_retrieve_response_with_empty_usage_dict(mocker):
    """Test that empty usage dict is handled gracefully."""
    mock_client = mocker.Mock()

    output_item = mocker.Mock()
    output_item.type = "message"
    output_item.role = "assistant"
    output_item.content = "Test response empty usage"
    output_item.tool_calls = []

    # Mock usage information as empty dict (tokens are 0 or missing)
    response_obj = mocker.Mock()
    response_obj.id = "resp-empty-usage"
    response_obj.output = [output_item]
    response_obj.usage = {}  # Empty dict

    mock_client.responses.create = mocker.AsyncMock(return_value=response_obj)
    mock_vector_stores = mocker.Mock()
    mock_vector_stores.data = []
    mock_client.vector_stores.list = mocker.AsyncMock(return_value=mock_vector_stores)

    mocker.patch("app.endpoints.query_v2.get_system_prompt", return_value="PROMPT")
    mocker.patch("app.endpoints.query_v2.configuration", mocker.Mock(mcp_servers=[]))

    qr = QueryRequest(query="hello")
    summary, conv_id, _referenced_docs, token_usage = await retrieve_response(
        mock_client, "model-empty-usage", qr, token="tkn", provider_id="test-provider"
    )

    assert conv_id == "resp-empty-usage"
    assert summary.llm_response == "Test response empty usage"
    assert token_usage.input_tokens == 0
    assert token_usage.output_tokens == 0
    assert token_usage.llm_calls == 1  # Always 1, even when no token usage data


@pytest.mark.asyncio
async def test_retrieve_response_validates_attachments(mocker):
    """Test that retrieve_response validates attachments and includes them in the input string."""
    mock_client = mocker.Mock()
    response_obj = mocker.Mock()
    response_obj.id = "resp-4"
    response_obj.output = []
    response_obj.usage = None
    mock_client.responses.create = mocker.AsyncMock(return_value=response_obj)
    mock_vector_stores = mocker.Mock()
    mock_vector_stores.data = []
    mock_client.vector_stores.list = mocker.AsyncMock(return_value=mock_vector_stores)

    mocker.patch("app.endpoints.query_v2.get_system_prompt", return_value="PROMPT")
    mocker.patch("app.endpoints.query_v2.configuration", mocker.Mock(mcp_servers=[]))

    validate_spy = mocker.patch(
        "app.endpoints.query_v2.validate_attachments_metadata", return_value=None
    )

    attachments = [
        Attachment(attachment_type="log", content_type="text/plain", content="x"),
    ]

    qr = QueryRequest(query="hello", attachments=attachments)
    _summary, _cid, _ref_docs, _token_usage = await retrieve_response(
        mock_client, "model-a", qr, token="tkn"
    )

    validate_spy.assert_called_once()
    # Verify that attachments are included in the input
    kwargs = mock_client.responses.create.call_args.kwargs
    assert "input" in kwargs
    # Input should be a string containing both query and attachment
    assert isinstance(kwargs["input"], str)
    assert "hello" in kwargs["input"]
    assert "[Attachment: log]" in kwargs["input"]
    assert "x" in kwargs["input"]


@pytest.mark.asyncio
async def test_query_endpoint_handler_v2_success(mocker, dummy_request):
    """Test successful query endpoint handler execution with proper response structure."""
    # Mock configuration to avoid configuration not loaded errors
    mock_config = mocker.Mock()
    mock_config.llama_stack_configuration = mocker.Mock()
    mock_config.quota_limiters = []
    mocker.patch("app.endpoints.query_v2.configuration", mock_config)

    mock_client = mocker.Mock()
    mock_client.models.list = mocker.AsyncMock(return_value=[mocker.Mock()])
    mocker.patch(
        "client.AsyncLlamaStackClientHolder.get_client", return_value=mock_client
    )
    mocker.patch("app.endpoints.query.evaluate_model_hints", return_value=(None, None))
    mocker.patch(
        "app.endpoints.query.select_model_and_provider_id",
        return_value=("llama/m", "m", "p"),
    )

    summary = mocker.Mock(llm_response="ANSWER", tool_calls=[], rag_chunks=[])
    token_usage = mocker.Mock(input_tokens=10, output_tokens=20)
    mocker.patch(
        "app.endpoints.query_v2.retrieve_response",
        return_value=(summary, "conv-1", [], token_usage),
    )
    mocker.patch("app.endpoints.query_v2.get_topic_summary", return_value="Topic")
    mocker.patch("app.endpoints.query.is_transcripts_enabled", return_value=False)
    mocker.patch("app.endpoints.query.persist_user_conversation_details")
    mocker.patch("utils.endpoints.store_conversation_into_cache")
    mocker.patch("app.endpoints.query.get_session")

    # Add missing mocks for quota functions
    mocker.patch("utils.quota.check_tokens_available")
    mocker.patch("utils.quota.consume_tokens")
    mocker.patch("utils.quota.get_available_quotas", return_value={})

    # Mock the request state
    dummy_request.state.authorized_actions = []

    res = await query_endpoint_handler_v2(
        request=dummy_request,
        query_request=QueryRequest(query="hi"),
        auth=("user123", "", False, "token-abc"),
        mcp_headers={},
    )

    assert res.conversation_id == "conv-1"
    assert res.response == "ANSWER"


@pytest.mark.asyncio
async def test_query_endpoint_handler_v2_api_connection_error(mocker, dummy_request):
    """Test that query endpoint handler properly handles and reports API connection errors."""
    # Mock configuration to avoid configuration not loaded errors
    mock_config = mocker.Mock()
    mock_config.llama_stack_configuration = mocker.Mock()
    mocker.patch("app.endpoints.query_v2.configuration", mock_config)

    def _raise(*_args, **_kwargs):
        raise APIConnectionError(request=None)

    mocker.patch("client.AsyncLlamaStackClientHolder.get_client", side_effect=_raise)

    fail_metric = mocker.patch("metrics.llm_calls_failures_total")

    with pytest.raises(HTTPException) as exc:
        await query_endpoint_handler_v2(
            request=dummy_request,
            query_request=QueryRequest(query="hi"),
            auth=("user123", "", False, "token-abc"),
            mcp_headers={},
        )

    assert exc.value.status_code == status.HTTP_500_INTERNAL_SERVER_ERROR
    assert "Unable to connect to Llama Stack" in str(exc.value.detail)
    fail_metric.inc.assert_called_once()
